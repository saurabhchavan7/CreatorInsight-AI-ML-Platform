{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d3e388",
   "metadata": {},
   "source": [
    "#### Data Preprocessing post 02_eda_v1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e935f251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e433862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/interim/reddit_preprocessed_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b36c8a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0  family mormon have never tried explain them th...         1\n",
       "1  buddhism has very much lot compatible with chr...         1\n",
       "2  seriously don say thing first all they won get...        -1\n",
       "3  what you have learned yours and only yours wha...         0\n",
       "4  for your own benefit you may want read living ...         1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c64d7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df = df[~(df['clean_comment'].str.strip() == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f77c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing function\n",
    "def preprocess_comment(comment):\n",
    "    # Convert to lowercase\n",
    "    comment = comment.lower()\n",
    "\n",
    "    # Remove trailing and leading whitespaces\n",
    "    comment = comment.strip()\n",
    "\n",
    "    # Remove newline characters\n",
    "    comment = re.sub(r'\\n', ' ', comment)\n",
    "\n",
    "    # Remove non-alphanumeric characters, except punctuation\n",
    "    comment = re.sub(r'[^A-Za-z0-9\\s!?.,]', '', comment)\n",
    "\n",
    "    # Remove stopwords but retain important ones for sentiment analysis\n",
    "    stop_words = set(stopwords.words('english')) - {'not', 'but', 'however', 'no', 'yet'}\n",
    "    comment = ' '.join([word for word in comment.split() if word not in stop_words])\n",
    "\n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    comment = ' '.join([lemmatizer.lemmatize(word) for word in comment.split()])\n",
    "\n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43860a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing function to the 'clean_comment' column\n",
    "df['clean_comment'] = df['clean_comment'].apply(preprocess_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd5578ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_comment'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8734b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../data/interim/reddit_preprocessed_v2.csv', index=False)\n",
    "df.to_csv('../../data/processed/reddit_clean_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfa42156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\n",
    "    '../../data/processed/reddit_clean_final.csv',\n",
    "    keep_default_na=False,\n",
    "    na_filter=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2658afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['clean_comment'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb91fb",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "IMPORTANT NOTE — WHY WE USE keep_default_na=False & na_filter=False WHEN LOADING CSV\n",
    "\n",
    "Problem:\n",
    "--------\n",
    "After preprocessing, df['clean_comment'] had 0 nulls.\n",
    "However, after saving to CSV and reloading, exactly 123 nulls appeared again.\n",
    "\n",
    "Root Cause:\n",
    "-----------\n",
    "Pandas automatically interprets certain strings as missing values\n",
    "(even if they are legitimate text in our dataset).\n",
    "\n",
    "By default, these strings turn INTO NaN when reading CSV:\n",
    "\n",
    "    \"NA\", \"N/A\", \"na\", \"Na\", \"NULL\", \"None\", \"null\", \"#N/A\", \"\"\n",
    "\n",
    "In our cleaned dataset, some comments legitimately contained words like:\n",
    "    \"NA\", \"None\", \"Null\"\n",
    "\n",
    "Even though the cleaned DataFrame had no NaNs before saving, \n",
    "Pandas converted these values into NaN on reload.\n",
    "\n",
    "Solution:\n",
    "---------\n",
    "Disable Pandas’ default NA detection when loading the CSV:\n",
    "\n",
    "    keep_default_na=False  → don't convert special strings to NaN\n",
    "    na_filter=False        → don't detect missing values at all\n",
    "\n",
    "This ensures the text is preserved EXACTLY as saved.\n",
    "\n",
    "Usage:\n",
    "------\n",
    "df.to_csv(..., quoting=1, encoding='utf-8')   # save safely\n",
    "df = pd.read_csv(..., keep_default_na=False, na_filter=False)  # load safely\n",
    "\n",
    "This guarantees that NO unintended NaNs appear again after reloading.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2252104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b9e0e14",
   "metadata": {},
   "source": [
    "next will perform eda for the exploration of cleaned data in 04_eda_v2.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
